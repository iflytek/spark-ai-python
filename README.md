# è®¯é£æ˜Ÿç«å¤§æ¨¡å‹æ¥å…¥åº“ (spark-ai-python)

æœ¬Python SDKåº“å¸®åŠ©ç”¨æˆ·æ›´å¿«ä½“éªŒè®¯é£æ˜Ÿç«å¤§æ¨¡å‹

## é¡¹ç›®åœ°å€

* Github: [https://github.com/iflytek/spark-ai-python](https://github.com/iflytek/spark-ai-python)
æ¬¢è¿ç‚¹èµï¼Œstar

## å‰è¨€

é•¿ä¹…ä»¥æ¥ï¼Œpythonæ¥å…¥æ˜Ÿç«å¤§æ¨¡å‹æ²¡æœ‰ä¸€ä¸ªç»Ÿä¸€å®˜æ–¹ç»´æŠ¤çš„Libraryï¼Œ
æ­¤ç•ªå¼€æºæœ¬sdkï¼Œä¹Ÿæ˜¯ä¸ºäº†èƒ½å¤Ÿè®©æ˜Ÿç«å¤§æ¨¡å‹æ›´å¿«è½åˆ°å®é™…çš„ä¸€äº›AIå¤§æ¨¡å‹åº”ç”¨ç›¸å…³çš„å¼€å‘ä»»åŠ¡ä¸­å»ï¼Œç®€åŒ–pythonç”¨æˆ·è°ƒç”¨å¤§æ¨¡å‹æˆæœ¬ã€‚

ç›®å‰åŸºäºLangchainçš„ä¸€äº›åŸºç¡€æ•°æ®ç±»å‹ç§»æ¤å¼€å‘å¾—åˆ°æœ¬é¡¹ç›®ï¼Œéƒ¨åˆ†æ ¸å¿ƒå®ç°å¦‚æœ‰é›·åŒï¼Œçº¯å±"å­¦ä¹ "ï¼
æ„Ÿè°¢å¼€æºçš„åŠ›é‡ï¼Œå¸Œæœ›è®¯é£å¼€æºè¶Šåšè¶Šå¥½ï¼Œæ˜Ÿç«å¤§æ¨¡å‹æ•ˆæœè¶Šæ¥è¶Šå¥½ï¼ã€‚


![!img](log.jpg)

**æœ¬logoå‡ºè‡ª[æ˜Ÿç«å¤§æ¨¡å‹](https://xinghuo.xfyun.cn/)**

***æ„Ÿè°¢ç¤¾åŒº(Langchainé¡¹ç›®ä»¥åŠSparkLLMéƒ¨åˆ†committer)[é¡¹ç›®æ­£åœ¨å¼€å‘ä¸­]***


## æ–°ç‰¹æ€§ï¼ï¼ğŸ‘‰ğŸ‘‰ğŸ‘‰ç”Ÿæ€å¯¹æ¥

- [x] æ”¯æŒLLamaIndex,è¯¦ç»†ç”¨æ³•è¯·å‚è€ƒ [LLamIndex Support](#llama_index)
- [x] æ”¯æŒAutoGen,è¯¦ç»†ç”¨æ³•è¯·å‚è€ƒ [AutoGen Support](#autogen)

## è¿‘æœŸè§„åˆ’æ–°ç‰¹æ€§[å¾…æ¼”è¿›]

- [x] å¼€æºæ¡†æ¶AutoGPT/AutoGen/MetaGpt/Langchain/PromptFlow/.... å¿«é€Ÿé›†æˆæ˜Ÿç«ç¤ºä¾‹
- [x] æç®€çš„æ¥å…¥,å¿«é€Ÿè°ƒç”¨è®¯é£æ˜Ÿç«å¤§æ¨¡å‹
- [x] å·²å‘å¸ƒpypi [å›½å†…æºå‡å¯å®‰è£…]
- [x] æœ¬åœ°ä»£ç†æ–¹å¼æ˜Ÿç«SparkAPIè½¬OpenAIæ¥å£(è®©ä½ å¿«é€Ÿåœ¨å¼€æºagentæ¡†æ¶é›†æˆæ˜Ÿç«å¤§æ¨¡å‹)
- [ ] SDKæ–¹å¼é€‚é…OpenAIæ¥å£ ChatCompletionæ¥å£ 
- [ ] SDKæ–¹å¼é€‚é…OpenAI Embeddingæ¥å£
- [ ] æ— ç¼å¯¹æ¥[è®¯é£Maaså¹³å°](https://training.xfyun.cn/)å¾®è°ƒè®­ç»ƒæ‰˜ç®¡çš„å¤§æ¨¡å‹API
- [ ] æ”¯æŒ HTTP SPARK API
- [ ] æ”¯æŒå¤§æ¨¡å‹å¤šæ¨¡æ€ç­‰èƒ½åŠ›
- [ ] Golangç‰ˆæœ¬[SDK](https://github.com/iflytek/spark-ai-go/)è¿›è¡Œä¸­
- [ ] å¯¹æ¥ [liteLLM](https://github.com/BerriAI/litellm)



## å®‰è£…

**é¡¹ç›®ä»…æ”¯æŒ Python3.8+**

å¦‚æœä½ ä¸éœ€è¦æºç ï¼Œåªéœ€è¦é€šè¿‡ `pip `å¿«é€Ÿå®‰è£…

```sh
pip install --upgrade spark_ai_python
```
å›½å†…ä½¿ç”¨:
```bash
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple spark_ai_python
```

Install from source with:

```sh
python setup.py install
```

## å¦‚ä½•ä½¿ç”¨

### ç¤ºä¾‹ä»£ç 

* å‰ç½®æ¡ä»¶
  éœ€è¦åœ¨ xfyun.cn ç”³è¯·æœ‰æƒé™çš„
  * app_id
  * api_key
  * api_secret

* URL/Domainé…ç½®è¯·æŸ¥çœ‹[doc](https://www.xfyun.cn/doc/spark/Web.html#_1-%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E)
* è¿è¡Œæµ‹è¯•è„šæœ¬éœ€è¦æå‰å°† `.env.example` æ‹·è´ä¸º `.env`å¹¶é…ç½®å…¶ä¸­å˜é‡

### ä¸€æ¬¡æ€§è¿”å›ç»“æœ(éæµå¼)

tests/examples/llm_test.py

```python
import os

from sparkai.llm.llm import ChatSparkLLM, ChunkPrintHandler
from sparkai.core.messages import ChatMessage
try:
    from dotenv import load_dotenv
except ImportError:
    raise RuntimeError('Python environment for SPARK AI is not completely set up: required package "python-dotenv" is missing.') from None

load_dotenv()

if __name__ == '__main__':
    from sparkai.core.callbacks import StdOutCallbackHandler
    messages = [{'role': 'user',
                 'content': 'ä½ å¥½å‘€'}]

    spark = ChatSparkLLM(
        spark_api_url=os.environ["SPARKAI_URL"],
        spark_app_id=os.environ["SPARKAI_APP_ID"],
        spark_api_key=os.environ["SPARKAI_API_KEY"],
        spark_api_secret=os.environ["SPARKAI_API_SECRET"],
        spark_llm_domain=os.environ["SPARKAI_DOMAIN"],
        streaming=False,
    )
    messages = [ChatMessage(
        role="user",
        content=messages[0]['content']

    )]
    handler = ChunkPrintHandler()
    a = spark.generate([messages], callbacks=[handler])
    print(a)
```
æ³¨æ„å½“`streaming`è®¾ç½®ä¸º `False`çš„æ—¶å€™, callbacks å¹¶ä¸èµ·ä½œç”¨ã€‚

### æµå¼è¿”å›ç»“æœ

tests/examples/llm_test.py

```python
import os

from sparkai.llm.llm import ChatSparkLLM, ChunkPrintHandler
from sparkai.core.messages import ChatMessage
try:
    from dotenv import load_dotenv
except ImportError:
    raise RuntimeError('Python environment for SPARK AI is not completely set up: required package "python-dotenv" is missing.') from None

load_dotenv()
def test_stream():
    from sparkai.core.callbacks import StdOutCallbackHandler
    messages = [{'role': 'user',
                 'content': 'ä½œä¸ºAutoSparkçš„åˆ›å»ºè€…è§’è‰²ï¼Œå½“å‰éœ€è¦ä½ å¸®æˆ‘åˆ†æå¹¶ç”Ÿæˆä»»åŠ¡ï¼Œä½ å½“å‰ä¸»è¦ç›®æ ‡æ˜¯:\n1. å¸®æˆ‘å†™ä¸ªè´ªåƒè›‡pythonæ¸¸æˆ\n\n\n\n\nå½“å‰æ‰§è¡Œä»»åŠ¡èŠ‚ç‚¹æ˜¯: `ç¼–å†™è´ªåƒè›‡æ¸¸æˆçš„ç•Œé¢è®¾è®¡`\n\nä»»åŠ¡æ‰§è¡Œå†å²æ˜¯:\n`\nTask: ä½¿ç”¨ThinkingToolåˆ†æè´ªåƒè›‡æ¸¸æˆçš„éœ€æ±‚\nResult: Error2: {\'error\': \'Could not parse invalid format: æ ¹æ®ä»»åŠ¡èŠ‚ç‚¹ï¼Œæˆ‘å°†ä½¿ç”¨ThinkingToolæ¥åˆ†æè´ªåƒè›‡æ¸¸æˆçš„éœ€æ±‚ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ç†è§£æ¸¸æˆçš„åŸºæœ¬åŠŸèƒ½å’Œè§„åˆ™ã€‚è´ªåƒè›‡æ¸¸æˆçš„ä¸»è¦ç›®æ ‡æ˜¯æ§åˆ¶ä¸€æ¡è›‡åœ¨å±å¹•ä¸Šç§»åŠ¨ï¼Œåƒåˆ°é£Ÿç‰©åè›‡ä¼šå˜é•¿ï¼Œç¢°åˆ°è‡ªå·±çš„èº«ä½“æˆ–è€…å±å¹•è¾¹ç¼˜åˆ™æ¸¸æˆç»“æŸã€‚\\n\\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨CodingToolæ¥ç¼–å†™è´ªåƒè›‡æ¸¸æˆçš„ä»£ç ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä»¥ä¸‹æ ¸å¿ƒç±»å’Œæ–¹æ³•ï¼š\\n\\n1. Snakeç±»ï¼šç”¨äºè¡¨ç¤ºè´ªåƒè›‡çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬è›‡çš„èº«ä½“ã€ç§»åŠ¨æ–¹å‘ç­‰ã€‚\\n2. Foodç±»ï¼šç”¨äºè¡¨ç¤ºé£Ÿç‰©çš„ä½ç½®ã€‚\\n3. Gameç±»ï¼šç”¨äºæ§åˆ¶æ¸¸æˆçš„è¿›è¡Œï¼ŒåŒ…æ‹¬åˆå§‹åŒ–æ¸¸æˆã€æ›´æ–°è›‡çš„ä½ç½®ã€æ£€æŸ¥ç¢°æ’ç­‰ã€‚\\n4. mainå‡½æ•°ï¼šç”¨äºå¯åŠ¨æ¸¸æˆã€‚\\n\\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿™äº›ç±»å’Œæ–¹æ³•çš„ä»£ç å†™å…¥æ–‡ä»¶ä¸­ã€‚\\n\\næœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨WriteTestToolæ¥ç¼–å†™æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿æˆ‘ä»¬çš„ä»£ç èƒ½å¤Ÿæ­£ç¡®åœ°è¿è¡Œã€‚æµ‹è¯•ç”¨ä¾‹åº”è¯¥åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š\\n\\n1. æµ‹è¯•æ¸¸æˆæ˜¯å¦èƒ½æ­£ç¡®åˆå§‹åŒ–ã€‚\\n2. æµ‹è¯•è›‡æ˜¯å¦èƒ½æ­£ç¡®ç§»åŠ¨ã€‚\\n3. æµ‹è¯•è›‡æ˜¯å¦èƒ½æ­£ç¡®åƒåˆ°é£Ÿç‰©å¹¶å˜é•¿ã€‚\\n4. æµ‹è¯•è›‡æ˜¯å¦èƒ½æ­£ç¡®ç¢°åˆ°è‡ªå·±çš„èº«ä½“æˆ–å±å¹•è¾¹ç¼˜å¯¼è‡´æ¸¸æˆç»“æŸã€‚ exceptionNot get command from llm response...\'}. \nTask: ç¼–å†™è´ªåƒè›‡æ¸¸æˆçš„specæ–‡ä»¶\nResult: Error2: {\'error\': \'Could not parse invalid format: æ ¹æ®ä»»åŠ¡èŠ‚ç‚¹ï¼Œæˆ‘å°†ä½¿ç”¨`WriteSpecTool`æ¥ç¼–å†™è´ªåƒè›‡æ¸¸æˆçš„specæ–‡ä»¶ã€‚\\n\\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä»¥ä¸‹æ ¸å¿ƒç±»å’Œæ–¹æ³•ï¼š\\n1. Snakeç±»ï¼šç”¨äºè¡¨ç¤ºè´ªåƒè›‡çš„çŠ¶æ€ï¼ŒåŒ…æ‹¬è›‡çš„èº«ä½“ã€ç§»åŠ¨æ–¹å‘ç­‰ã€‚\\n2. Foodç±»ï¼šç”¨äºè¡¨ç¤ºé£Ÿç‰©çš„ä½ç½®ã€‚\\n3. Gameç±»ï¼šç”¨äºæ§åˆ¶æ¸¸æˆçš„è¿›è¡Œï¼ŒåŒ…æ‹¬åˆå§‹åŒ–æ¸¸æˆã€æ›´æ–°è›‡çš„ä½ç½®ã€æ£€æŸ¥ç¢°æ’ç­‰ã€‚\\n4. mainå‡½æ•°ï¼šç”¨äºå¯åŠ¨æ¸¸æˆã€‚\\n\\næ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¿™äº›ç±»å’Œæ–¹æ³•çš„ä»£ç å†™å…¥æ–‡ä»¶ä¸­ã€‚\\n\\næœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`WriteTestTool`æ¥ç¼–å†™æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿æˆ‘ä»¬çš„ä»£ç èƒ½å¤Ÿæ­£ç¡®åœ°è¿è¡Œã€‚æµ‹è¯•ç”¨ä¾‹åº”è¯¥åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š\\n1. æµ‹è¯•æ¸¸æˆæ˜¯å¦èƒ½æ­£ç¡®åˆå§‹åŒ–ã€‚\\n2. æµ‹è¯•è›‡æ˜¯å¦èƒ½æ­£ç¡®ç§»åŠ¨ã€‚\\n3. æµ‹è¯•è›‡æ˜¯å¦èƒ½æ­£ç¡®åƒåˆ°é£Ÿç‰©å¹¶å˜é•¿ã€‚\\n4. æµ‹è¯•è›‡æ˜¯å¦èƒ½æ­£ç¡®ç¢°åˆ°è‡ªå·±çš„èº«ä½“æˆ–å±å¹•è¾¹ç¼˜å¯¼è‡´æ¸¸æˆç»“æŸã€‚ exceptionNot get command from llm response...\'}. \n\n`\n\næ ¹æ®ä¸Šè¿°èƒŒæ™¯ä¿¡æ¯ï¼Œä½ çš„ä»»åŠ¡æ˜¯éœ€è¦ç†è§£å½“å‰çš„ä»»åŠ¡èŠ‚ç‚¹å…³é”®ä¿¡æ¯ï¼Œåˆ›å»ºä¸€ä¸ªè§„åˆ’ï¼Œè§£é‡Šä¸ºä»€ä¹ˆè¦è¿™ä¹ˆåšï¼Œå¹¶ä¸”æåŠä¸€äº›éœ€è¦æ³¨æ„çš„äº‹é¡¹ï¼Œå¿…é¡»ä»ä¸‹è¿°TOOLSä¸­æŒ‘é€‰ä¸€ä¸ªå‘½ä»¤ç”¨äºä¸‹ä¸€æ­¥æ‰§è¡Œã€‚\n\nTOOLS:\n1. "ThinkingTool": Intelligent problem-solving assistant that comprehends tasks, identifies key variables, and makes efficient decisions, all while providing detailed, self-driven reasoning for its choices. Do not assume anything, take the details from given data only., args : task_description: "<task_description>",\n2. "WriteSpecTool": A tool to write the spec of a program., args : task_description: "<task_description>",spec_file_name: "<spec_file_name>",\n3. "CodingTool": You will get instructions for code to write. You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code. Think step by step and reason yourself to the right decisions to make sure we get it right. You will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose. Then you will output the content of each file including ALL code., args : code_description: "<code_description>",\n4. "WriteTestTool": æ‚¨æ˜¯ä¸€ä½è¶…çº§èªæ˜çš„å¼€å‘äººå‘˜ï¼Œä½¿ç”¨æµ‹è¯•é©±åŠ¨å¼€å‘æ ¹æ®è§„èŒƒç¼–å†™æµ‹è¯•ã€‚\nè¯·æ ¹æ®ä¸Šè¿°è§„èŒƒç”Ÿæˆæµ‹è¯•ã€‚æµ‹è¯•åº”è¯¥å°½å¯èƒ½ç®€å•ï¼Œ ä½†ä»ç„¶æ¶µç›–äº†æ‰€æœ‰åŠŸèƒ½ã€‚\nå°†å®ƒä»¬å†™å…¥æ–‡ä»¶ä¸­, args : test_description: "<test_description>",test_file_name: "<test_file_name>",\n\n\n\nçº¦æŸæ¡ä»¶:\n1. è¯·æ³¨æ„è¿”å›çš„å‘½ä»¤åç§°å’Œå‚æ•°ä¸è¦è¢«å¼•å·åŒ…è£¹\n2. å‘½ä»¤åç§°å¿…é¡»æ˜¯TOOLSä¸­çš„å·²çŸ¥çš„\n3. ä½ åªèƒ½ç”Ÿæˆä¸€ä¸ªå¾…æ‰§è¡Œå‘½ä»¤åç§°åŠå…¶å¯¹åº”å‚æ•°\n4. ä½ ç”Ÿæˆçš„å‘½ä»¤å¿…é¡»æ˜¯ç”¨æ¥è§£å†³ `ç¼–å†™è´ªåƒè›‡æ¸¸æˆçš„ç•Œé¢è®¾è®¡`\n\nåœ¨ä¹‹åçš„æ¯æ¬¡å›ç­”ä¸­ï¼Œä½ å¿…é¡»ä¸¥æ ¼éµä»ä¸Šè¿°çº¦æŸæ¡ä»¶å¹¶æŒ‰ç…§å¦‚ä¸‹JsonSchemaçº¦æŸè¿”å›å“åº”:\n\n{\n "$schema": "http://json-schema.org/draft-07/schema#",\n "type": "object",\n "properties": {\n "thoughts": {\n "type": "object",\n "properties": {\n "reasoning": {\n "type": "string",\n "description": "short reasoning",\n }\n },\n "required": ["reasoning"]\n },\n "tool": {\n "type": "object",\n "properties": {\n "name": {\n "type": "string",\n "description": "tool name",\n },\n "args": {\n "type": "object",\n "description": "tool arguments",\n }\n },\n "required": ["name", "args"]\n }\n }\n}'}]

    spark = ChatSparkLLM(
        spark_api_url=os.environ["SPARKAI_URL"],
        spark_app_id=os.environ["SPARKAI_APP_ID"],
        spark_api_key=os.environ["SPARKAI_API_KEY"],
        spark_api_secret=os.environ["SPARKAI_API_SECRET"],
        spark_llm_domain=os.environ["SPARKAI_DOMAIN"],
        streaming=True,

    )
    messages = [ChatMessage(
        role="user",
        content=messages[0]['content']

    )]
    handler = ChunkPrintHandler()
    a = spark.generate([messages], callbacks=[handler])
    print(a)
```

å…¶ä¸­ `ChunkPrintHandler` ä¸ºå›è°ƒç±»ï¼Œå¯ä»¥åœ¨å›è°ƒç±»å¤„ç†æµå¼å“åº”çš„chunkï¼Œ
è¯¥ç±»ç®€å•å®ç°å¦‚ä¸‹:

```python
class ChunkPrintHandler(BaseCallbackHandler):
    """Callback Handler that prints to std out."""

    def __init__(self, color: Optional[str] = None) -> None:
        """Initialize callback handler."""
        self.color = color

    def on_llm_new_token(self,  token: str,
        *,
        chunk:  None,
        **kwargs: Any,):
        print(token)

```
ä¸Šè¿°åœ¨ on_llm_new_token å®ç°æ‚¨çš„æµå¼å¤„ç†é€»è¾‘,å¦‚éœ€å®šåˆ¶æµå¼å¤„ç†é€»è¾‘ï¼Œè¯·å‚è€ƒä¸Šè¿°å®ç°ï¼Œç»§æ‰¿: BaseCallbackHandler

### FunctionCallåŠŸèƒ½
æ¯”å¦‚å°† mulitply ä¹˜æ³•å‡½æ•°å®šä¹‰ä¼ å…¥ ChatSparkLLM

```python
def multiply(a,b :int) -> int:
    """ä¹˜æ³•å‡½æ•°ï¼Œ
    Args:
        a: è¾“å…¥a
        b: è¾“å…¥b
    Return:
         è¿”å› a*b ç»“æœ
    """
    print("hello success")
    return a*b

def test_function_call():
    from sparkai.core.callbacks import StdOutCallbackHandler
    messages = [{'role': 'user',
                 'content': "å¸®æˆ‘ç®—ä¸‹ 12ä¹˜ä»¥12"}]
    spark = ChatSparkLLM(
        spark_api_url=os.environ["SPARKAI_URL"],
        spark_app_id=os.environ["SPARKAI_APP_ID"],
        spark_api_key=os.environ["SPARKAI_API_KEY"],
        spark_api_secret=os.environ["SPARKAI_API_SECRET"],
        spark_llm_domain=os.environ["SPARKAI_DOMAIN"],
        streaming=False,

    )
    function_definition = [convert_to_openai_tool(multiply)]
    print(json.dumps(convert_to_openai_tool(multiply),ensure_ascii=False))
    messages = [ChatMessage(
        role="user",
        content=messages[0]['content']

    )]
    handler = ChunkPrintHandler()
    a = spark.generate([messages], callbacks=[handler],function_definition=function_definition)
    print(a)
    print(a.generations[0][0].text) 
    print(a.llm_output)
```
å¾—åˆ°è¾“å‡º

```bash
PASSED                                   [100%]{"type": "function", "function": {"name": "multiply", "description": "ä¹˜æ³•å‡½æ•°ï¼Œ\nArgs:\n    a: è¾“å…¥a\n    b: è¾“å…¥b\nReturn:\n     è¿”å› a*b ç»“æœ", "parameters": {"type": "object", "properties": {"b": {"type": "integer"}}, "required": ["a", "b"]}}}
generations=[[ChatGeneration(message=FunctionCallMessage(content='', function_call={'arguments': '{"a":12,"b":12}', 'name': 'multiply'}))]] llm_output={'token_usage': {'question_tokens': 9, 'prompt_tokens': 9, 'completion_tokens': 0, 'total_tokens': 9}} run=[RunInfo(run_id=UUID('95bf4e2e-6c90-41aa-9ddf-51b707d4d3c7'))]

generations=[[ChatGeneration(message=FunctionCallMessage(content='', function_call={'arguments': '{"a":12,"b":12}', 'name': 'operator_multiply'}))]] llm_output={'token_usage': {'question_tokens': 9, 'prompt_tokens': 9, 'completion_tokens': 0, 'total_tokens': 9}} run=[RunInfo(run_id=UUID('64bb65bd-948b-4354-bb72-e6847cc0a21b'))]

{'token_usage': {'question_tokens': 9, 'prompt_tokens': 9, 'completion_tokens': 0, 'total_tokens': 9}}

```

### æœ¬åœ°ä»£ç†æ–¹å¼æ˜Ÿç«SparkAPIè½¬OpenAIæ¥å£ 

**ä»…ä¾›ç”¨äºè°ƒè¯•æˆ–è€…åº”ç”¨äºä¸‰æ–¹æ¡†æ¶å¿«é€Ÿé›†æˆæ˜Ÿç«**

```python
python -m sparkai.spark_proxy.main 
```
è¿è¡Œåå¦‚ä¸‹:

```bash
INFO:     Started server process [57295]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8008 (Press CTRL+C to quit)

```

ä¹‹åå†éœ€è¦é…ç½®`OPENAI`é…ç½®ä¸Šè¿° æœ¬åœ°url å’Œ æ˜Ÿç« ```key&secret&appid"```ç»„æˆçš„keyå³å¯ä»¥openaiæ¥å£å½¢å¼è°ƒç”¨æ˜Ÿç«å¤§æ¨¡å‹

* open_api_key: é…ç½®æ ¼å¼keyä¸º: ```key&secret&appid"``` æ ¼å¼çš„key
* openai_base_url: ä½ æœ¬åœ° ip:8008ç«¯å£

å…·ä½“æ“ä½œæµç¨‹å‚è§[æœ¬åœ°ä»£ç†æ–¹å¼æ˜Ÿç«SparkAPIè½¬OpenAIæ¥å£ ](tests/examples/docs/proxy_open_ai.md)


## ç”Ÿæ€æ”¯æŒ

<h3 id="llama_index">LLamaIndex Support</h3>

```python
### çœç•¥å…¶ä»–ä»£ç 
import os
## å¼•å…¥æ˜Ÿç«spark-ai -python 
from sparkai.frameworks.llama_index import SparkAI

from llama_index.core import SimpleDirectoryReader, StorageContext, VectorStoreIndex, Settings
from llama_index.core.embeddings import resolve_embed_model
from llama_index.vector_stores.chroma import ChromaVectorStore

class XXXX:
    def query(self,q):
        # Query Data
        chroma_collection = self.chroma_client.get_or_create_collection("quickstart")
        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)

        index = VectorStoreIndex.from_vector_store(
            vector_store,
            embed_model=self.embed_model,
        )
        sparkai = SparkAI(
            spark_api_url=os.environ["SPARKAI_URL"],
            spark_app_id=os.environ["SPARKAI_APP_ID"],
            spark_api_key=os.environ["SPARKAI_API_KEY"],
            spark_api_secret=os.environ["SPARKAI_API_SECRET"],
            spark_llm_domain=os.environ["SPARKAI_DOMAIN"],
            streaming=False,
        )
        # Query Data from the persisted index
        query_engine = index.as_query_engine(llm=sparkai,similarity_top_k=4)
        response = query_engine.query(q)
        print(response)
        #display(Markdown(f"<b>{response}</b>"))
```

ç¤ºä¾‹ç»“æœå¦‚ä¸‹:

![img](tests/examples/spark_llama_index.png)


<h3 id="autogen">AutoGen Support</h3>

å¾®è½¯å‡ºå“çš„[AutoGen](https://github.com/microsoft/autogen)æ˜¯ä¸šç•Œå‡ºåçš„å¤šAgentæ™ºèƒ½ä½“æ¡†æ¶ã€‚
é€šè¿‡å‡ è¡ŒImportå³å¯è®©autogenåŸç”Ÿæ”¯æŒ[ã€æ˜Ÿç«å¤§æ¨¡å‹ã€‘](https://github.com/microsoft/autogen)

```python
from sparkai.frameworks.autogen import SparkAI
import autogen
from autogen.agentchat.contrib.retrieve_assistant_agent import RetrieveAssistantAgent

spark_config = autogen.config_list_from_json(
    "sparkai_autogen.json",
    filter_dict={"model_client_cls": ["SparkAI"]},
)
llm_config = {
    "timeout": 600,
    "cache_seed": None,  # change the seed for different trials
    "config_list": spark_config,
    "temperature": 0,
}

# 1. create an RetrieveAssistantAgent instance named "assistant"
assistant = RetrieveAssistantAgent(
    name="assistant",
    system_message="You are a helpful assistant.",
    llm_config=llm_config
)
# æ³¨å†ŒSparkAIç±»è¿›å…¥ agent
assistant.register_model_client(model_client_cls=SparkAI)

```
å…¶ä¸­`sparkai_autogen.json`å†…å®¹å¦‚ä¸‹:

***å…¶ä¸­æ˜Ÿç«çš„domainå¯¹åº” ä¸‹é¢é…ç½®model***

```json
[
  {
    "api_key": "<spark_api_key>&<spark_api_secret>&<spark_app_id>",
    "base_url": "wss://spark-api.xf-yun.com/v3.5/chat",
    "model_client_cls": "SparkAI",
    "model": "generalv3.5", 
    "stream": true,
    "params": {
      "request_timeout": 61
    }
  }
]


```
### è°ƒè¯•æ¨¡å¼

è®¾ç½®æ—¥å¿—çº§åˆ«:
```python
from sparkai.log.logger import logger
logger.setLevel("debug")
```


## æ¬¢è¿è´¡çŒ®

æ‰«ç åŠ å…¥äº¤æµç¾¤

![img](weichat.jpg)

## å·²çŸ¥é—®é¢˜

* é¡¹ç›®ç›®å‰å¼€å‘é˜¶æ®µï¼Œæœ‰ä¸€äº›å†—ä½™ä»£ç ï¼ŒäººåŠ›æœ‰é™ï¼Œéƒ¨åˆ†æ€æƒ³å€Ÿé‰´å¼€æºå®ç°

## URL

* wss://spark-api.xf-yun.com/v3.5/chat


## ğŸŒŸ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=iflytek/spark-ai-python&type=Date)](https://star-history.com/#iflytek/spark-ai-python&Date)

## è‡´è°¢

* [Langchain Community](https://github.com/hwchase17/langchain)
